---
title: "Machine Learning Project"
author: "Jason Goodman"
date: "June 22, 2014"
output: html_document
---

**Description**  
I chose to use a random forest using cross-validation across four folds instead of boosting, to speed up the computation. I built the model by eliminating all variables which mostly contained null values, as well as all variables which were not related to the data collected by the sensors, such as the user's name and the timestamps. I trained the algorithm on 70% of the data and tested on the remaining 30%. The model achieved an overall accuracy of 99.39% on the test data. The full confusion matrix is visible below.  

Note: The code ran fine in R, but had trouble running in the Rmd file. The full code and results are below, but they are not run in the Rmd file itself.  

**Code**  
Setting up:  
```
library(caret)
library(doMC)
registerDoMC(cores = 2)

## Download data
url = "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
training = read.csv(file=url)

url = "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testingFinal = read.csv(file=url)

## Split into training and testing for cross-validation
set.seed(10)
inTrain <- createDataPartition(y=training$classe, p=0.7, list=FALSE)
training2 <- training[inTrain,]
testing <- training[-inTrain,]

## Remove columns full of blanks or NAs, or if irrelevant (like user and timestamps)
result <- apply(training2, 2, function(x) length(which(!is.na(x) & (x!=""))))
keepCol <- ifelse(result > 285, T, F)
keepCol[c("X","user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",
                                        "cvtd_timestamp", "new_window", "num_window")] <- FALSE
training2 <- training2[,which(keepCol)]
testing2 <- testing[,which(keepCol)]
```

Running the random forest algorithm:    
```
modFit <- train(classe ~ .,data=training2,method="rf",prox=TRUE, 
                trControl = trainControl(method = "cv", number = 4, allowParallel=TRUE))
```

Testing the algorithm:  
```
pred <- predict(modFit,testing2)
confusionMatrix(pred, testing2$classe) 
```

```
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1674    6    0    0    0
         B    0 1126    7    0    1
         C    0    6 1016    8    2
         D    0    1    3  955    1
         E    0    0    0    1 1078

Overall Statistics
                                          
               Accuracy : 0.9939          
                 95% CI : (0.9915, 0.9957)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9923          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9886   0.9903   0.9907   0.9963
Specificity            0.9986   0.9983   0.9967   0.9990   0.9998
Pos Pred Value         0.9964   0.9929   0.9845   0.9948   0.9991
Neg Pred Value         1.0000   0.9973   0.9979   0.9982   0.9992
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2845   0.1913   0.1726   0.1623   0.1832
Detection Prevalence   0.2855   0.1927   0.1754   0.1631   0.1833
Balanced Accuracy      0.9993   0.9935   0.9935   0.9948   0.9980
```
